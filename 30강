30강
Bp 알고리즘은 3계층의 다층 신경망을 학습하는데 매우 유용하지만 은닉층의 수가 많아지면 학습이 매우 느려짐 그래서 심층 신경망이 널리 사용되었다.

신경망의 학습에서 매계변수(parameter)와 하이퍼 파라메터(hyper parameter)라는 용어가 사용 됨
매개변수
1.	학습에 의해 최적의 값이 결정되는,’가중치’와’바이어스(bias)’르르 매개변수라고 한다.
하이퍼 파라메터
1.	 매개변수 이외에 학습을 효과적으로 수행하기 위해 설정해야하는 많은 요소를 말함
초기 가중치는 신경망 학습에 있어서 가중치 초기화는 매우 중요하다
Xavier(자비에) 초기화
He(허) 초기화
비용함수(cost function)= 손실 함수(Loss function)이고 신경망 오차와 밀접한 관련이 있다
경사 하강법(gradient Descent)
평균제곱오차(Mean Square Error, mse)
1.	스그모이드 람수로 계속 미분을 한다면 매우 작아지기 때믄에 경사하강법으로 업데이트 하기가 어려워질 수 있다
교차 엔트로피 오차(cross-entropy error)
오버피팅(overfitting)= 과적합 언더피팅(underfitting)
1.	학습 데이터에 과도하게 특화되어 학습, 학습 데이터는 좋지만 새로운 데이터는 오이려 성능이 떨어진다
2.	언더피틴은 학습이 덜 되었다는 뜻
오버피팅 해결 방법
1.	정규화 (Regularization)
(1)	해결하기 위해 추가 정보를 도입
2.	드롭아웃(dropout)
(1)	입력층이나 은닉층의 일부 뉴런들을 삭제하고, 해당 뉴런들에 연결된 가중치들을 학습에서 제외시키는 방법
(2)	학습단계에서만 적용하고, 실제 응용은 모든 뉴런을 사용한다.
(3)	학습에서 제외되는 뉴런은 확률p갖ㅅ에 의해 랜덤하게 정한다.
